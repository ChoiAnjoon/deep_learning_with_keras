{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "C:\\Users\\MOON\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\datasets\\imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "C:\\Users\\MOON\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\datasets\\imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 500, 500)          1000500   \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 494, 32)           112032    \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 98, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 92, 32)            7200      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,119,765\n",
      "Trainable params: 1,119,765\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "max_features = 2000\n",
    "maxlen = 500\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = pad_sequences(x_test, maxlen=maxlen)\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, Conv1D, MaxPooling1D, GlobalMaxPooling1D\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features+1, maxlen, input_length=maxlen))\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미존재합니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "try:\n",
    "    os.mkdir('my_log_dir')\n",
    "except:\n",
    "    print('이미존재합니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "callbacks = [TensorBoard(\n",
    "                log_dir='my_log_dir', \n",
    "                histogram_fre-q=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "157/157 [==============================] - 9s 60ms/step - loss: 0.1369 - acc: 0.9786 - val_loss: 0.7603 - val_acc: 0.8690\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 9s 58ms/step - loss: 0.1159 - acc: 0.9844 - val_loss: 0.9061 - val_acc: 0.8660\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 9s 58ms/step - loss: 0.1018 - acc: 0.9872 - val_loss: 0.9442 - val_acc: 0.8714\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 9s 58ms/step - loss: 0.1028 - acc: 0.9873 - val_loss: 0.9914 - val_acc: 0.8690\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 9s 58ms/step - loss: 0.0868 - acc: 0.9916 - val_loss: 1.0298 - val_acc: 0.8632\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 9s 58ms/step - loss: 0.0943 - acc: 0.9891 - val_loss: 1.0982 - val_acc: 0.8666\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 9s 58ms/step - loss: 0.0864 - acc: 0.9901 - val_loss: 1.1207 - val_acc: 0.8654\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 9s 58ms/step - loss: 0.0927 - acc: 0.9910 - val_loss: 1.1617 - val_acc: 0.8650\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 9s 58ms/step - loss: 0.0886 - acc: 0.9902 - val_loss: 1.1817 - val_acc: 0.8682\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 9s 58ms/step - loss: 0.0835 - acc: 0.9924 - val_loss: 1.2914 - val_acc: 0.8588\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=10, batch_size=128, validation_split=0.2, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir=my_log_dir"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
